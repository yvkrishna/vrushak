{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "paddy classifer.ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyOi/nBLjXF6DSGPMdyzE5fE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yvkrishna/vrushak/blob/main/paddy_classifer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dC91dS90hYKH"
      },
      "source": [
        "!git clone https://github.com/yvkrishna/paddy_disease_classification.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azTtX3ecNoX8"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os \n",
        "from os import path\n",
        "from PIL import Image, ImageFilter, ImageDraw\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRAzE7xvhbFT"
      },
      "source": [
        "from tensorflow.keras.applications import InceptionResNetV2\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oU1-JYKBPAER"
      },
      "source": [
        "os.chdir('/content')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHO7qXc-nVeM"
      },
      "source": [
        "os.chdir('paddy_disease_classification/rice_leaf_diseases')\n",
        "path = os.getcwd()\n",
        "training_classes = [f.name for f in os.scandir(path) if f.is_dir()]\n",
        "print(training_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXHis6zDo1EY"
      },
      "source": [
        "def applyMedian(folder):\n",
        "  ''' \n",
        "    Applies Meadian Filter to all the images in the given folder. \n",
        "    Args : \n",
        "      Folder : (str). : Image_directory\n",
        "  '''\n",
        "  previous_path = os.getcwd()\n",
        "  os.chdir(folder)\n",
        "  current_path = os.getcwd()\n",
        "\n",
        "  for image in tqdm(list(os.listdir(current_path))):\n",
        "    img = cv2.imread(image)\n",
        "    # applies median filter to the image.\n",
        "    median = cv2.medianBlur(img, 5)\n",
        "    # saving the image by adding the blur feature.\n",
        "    im = Image.fromarray(median)\n",
        "    im.save(image)\n",
        "  os.chdir(previous_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYJQMPRM0hqw"
      },
      "source": [
        "for folder in training_classes:\n",
        "  applyMedian(folder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqoubpPR467k"
      },
      "source": [
        "os.chdir('/content')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRucI3QqVrVy"
      },
      "source": [
        "base_dir = 'paddy_disease_classification'\n",
        "train_dir = os.path.join(base_dir, 'rice_leaf_diseases')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkpRx2aY47C2"
      },
      "source": [
        "train_bact_leaf_smut_dir = os.path.join(train_dir, 'Bacterial leaf blight')  # directory with our training cat pictures\n",
        "train_brown_spot_dir = os.path.join(train_dir, 'Brown spot')  # directory with our training dog pictures\n",
        "train_leaf_smut_dir = os.path.join(train_dir, 'Leaf smut')  # directory with our training dog pictures"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBc67CSp5nPg"
      },
      "source": [
        "num_bact_leaf_smut_tr = len(os.listdir(train_bact_leaf_smut_dir))\n",
        "num_brown_spot_tr = len(os.listdir(train_brown_spot_dir))\n",
        "num_leaf_smut_tr = len(os.listdir(train_leaf_smut_dir))\n",
        "\n",
        "total_train = num_bact_leaf_smut_tr + num_brown_spot_tr + num_leaf_smut_tr\\"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-22gZwup6Nt-"
      },
      "source": [
        "print('Data before Data augumentation')\n",
        "print(\"--\")\n",
        "print('total training Bacterial leaf blight images:', num_bact_leaf_smut_tr)\n",
        "print('total training Brown spot images:', num_brown_spot_tr)\n",
        "print('total training Leaf smut images:', num_leaf_smut_tr)\n",
        "print(\"--\")\n",
        "print(\"Total training images:\", total_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aI3gETR08FP8"
      },
      "source": [
        "BATCH_SIZE = 20\n",
        "IMG_SHAPE  = 299"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9f2dvgsoC5nj"
      },
      "source": [
        "def rotateImages(rotationAmt,folder):\n",
        "  '''\n",
        "    rotateImages is used as one of the image augumentation techniques to \n",
        "    increase the dataset thereby increasing the accuracy.\n",
        "\n",
        "    rotateImages function rotates images in the current directory.\n",
        "\n",
        "   Args:\n",
        "   rotationAmt : int. The value of rotation in the image.\n",
        "   \n",
        "  '''\n",
        "  previous_path = os.getcwd()\n",
        "  os.chdir(folder)\n",
        "  current_path = os.getcwd()\n",
        "\n",
        "  total_images = 0\n",
        "\n",
        "  for image in tqdm(list(os.listdir(current_path))):\n",
        "    # check if the image is already rotated. \n",
        "    if (image.find(\"rot\") == -1): \n",
        "      img = Image.open(image)\n",
        "      # get the image name\n",
        "      img_name = list(image.split(\".\"))[0]\n",
        "      rotimg = img.rotate(rotationAmt)\n",
        "      # saving the image with its rotation information as well.\n",
        "      rotimg.save(img_name+\"rot\"+str(rotationAmt)+\".jpg\")\n",
        "      img.close()\n",
        "      total_images+=1\n",
        "  print(total_images)\n",
        "  os.chdir(previous_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZUcOdUkC5k7"
      },
      "source": [
        "def addBlur(folder):\n",
        "  '''\n",
        "    Adds Blur to the images.\n",
        "    This function will list out all the images in the current directory and \n",
        "    applies blur to the image and saves it in the same folder.\n",
        "  '''\n",
        "  previous_path = os.getcwd()\n",
        "  os.chdir(folder)\n",
        "  current_path = os.getcwd()\n",
        "  # for each image in the current directory\n",
        "  total_images = 0\n",
        "\n",
        "  for image in tqdm(list(os.listdir(current_path))):\n",
        "    if (image.find(\"rot\") == -1): \n",
        "      img = Image.open(image)\n",
        "      # adds blur to the image using ImageFilter.Blur\n",
        "      blured_image = img.filter(ImageFilter.BLUR)\n",
        "      # get the image name\n",
        "      img_name = list(image.split(\".\"))[0]\n",
        "      # saving the image by adding the blur feature.\n",
        "      blured_image.save(img_name+\"blur.jpg\")\n",
        "      total_images+=1\n",
        "  print(total_images)\n",
        "  os.chdir(previous_path)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lt58a9g4C5fm"
      },
      "source": [
        "def horizontalFlip(folder):\n",
        "  '''\n",
        "    Adds Blur to the images.\n",
        "    This function will list out all the images in the current directory and \n",
        "    applies blur to the image and saves it in the same folder.\n",
        "  '''\n",
        "  previous_path = os.getcwd()\n",
        "  os.chdir(folder)\n",
        "  current_path = os.getcwd()\n",
        "  # for each image in the current directory\n",
        "  total_images = 0\n",
        "\n",
        "  for image in tqdm(list(os.listdir(current_path))):\n",
        "    if (image.find(\"rot\") == -1 and image.find(\"blur\") == -1): \n",
        "      img = cv2.imread(image) \n",
        "      # Flips the image\n",
        "      flip = cv2.flip(img, 1)\n",
        "      # get the image name\n",
        "      img_name = list(image.split(\".\"))[0]\n",
        "      # saving the image by adding the flip feature.\n",
        "      cv2.imwrite(img_name+\"flip.jpg\",flip)\n",
        "      total_images+=1\n",
        "  print(total_images)\n",
        "  os.chdir(previous_path)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeSOsjGoGCuH"
      },
      "source": [
        "os.chdir('paddy_disease_classification/testing')\n",
        "for folder in training_classes:\n",
        "  # Rotating images of train_label_img_locations with an angle of 90 deg.\n",
        "  rotateImages(90,folder)\n",
        "\n",
        "  # Blur images in train_label_img_locations\n",
        "  addBlur(folder)\n",
        "\n",
        "  # # Adds Uniform Noise to images in train_label_img_locations\n",
        "  # addUniformNoise(folder)\n",
        "\n",
        "  # horizontally flips the images\n",
        "  horizontalFlip(folder)\n",
        "\n",
        "  print()\n",
        "os.chdir('/content')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2A1lUpv2fwY"
      },
      "source": [
        "os.chdir('paddy_disease_classification/rice_leaf_diseases')\n",
        "for folder in training_classes:\n",
        "  # Rotating images of train_label_img_locations with an angle of 90 deg.\n",
        "  rotateImages(90,folder)\n",
        "\n",
        "  # Blur images in train_label_img_locations\n",
        "  addBlur(folder)\n",
        "\n",
        "  # # Adds Uniform Noise to images in train_label_img_locations\n",
        "  # addUniformNoise(folder)\n",
        "\n",
        "  # horizontally flips the images\n",
        "  horizontalFlip(folder)\n",
        "\n",
        "  print()\n",
        "os.chdir('/content')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6wx_kdyLsv_"
      },
      "source": [
        "base_dir = 'paddy_disease_classification'\n",
        "train_dir = os.path.join(base_dir, 'rice_leaf_diseases')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpiY2M5qLswD"
      },
      "source": [
        "train_bact_leaf_smut_dir = os.path.join(train_dir, 'Bacterial leaf blight')  # directory with our training cat pictures\n",
        "train_brown_spot_dir = os.path.join(train_dir, 'Brown spot')  # directory with our training dog pictures\n",
        "train_leaf_smut_dir = os.path.join(train_dir, 'Leaf smut')  # directory with our training dog pictures"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ifsw_YPLswG"
      },
      "source": [
        "num_bact_leaf_smut_tr = len(os.listdir(train_bact_leaf_smut_dir))\n",
        "num_brown_spot_tr = len(os.listdir(train_brown_spot_dir))\n",
        "num_leaf_smut_tr = len(os.listdir(train_leaf_smut_dir))\n",
        "\n",
        "total_train = num_bact_leaf_smut_tr + num_brown_spot_tr + num_leaf_smut_tr\\"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlhcO3HwLswJ"
      },
      "source": [
        "print('Data after Data augumentation')\n",
        "print(\"--\")\n",
        "print('total training Bacterial leaf blight images:', num_bact_leaf_smut_tr)\n",
        "print('total training Brown spot images:', num_brown_spot_tr)\n",
        "print('total training Leaf smut images:', num_leaf_smut_tr)\n",
        "print(\"--\")\n",
        "print(\"Total training images:\", total_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HzxZiSMPA8l"
      },
      "source": [
        "os.chdir('paddy_disease_classification')\n",
        "!mkdir train\n",
        "os.chdir('/content')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Lclwc3hNPVL"
      },
      "source": [
        "def create_dataset(folder):\n",
        "  previous_path = os.getcwd()\n",
        "  os.chdir(folder)\n",
        "  current_path = os.getcwd()\n",
        "  # for each image in the current directory\n",
        "  total_images = 0\n",
        "\n",
        "  for image in tqdm(list(os.listdir(current_path))):\n",
        "\n",
        "    shutil.move(image, \"/content/paddy_disease_classification/train\")\n",
        "\n",
        "    if (folder=='Bacterial leaf blight'):\n",
        "      img_label[image] = np.asarray([1,0,0], dtype=np.float32)\n",
        "    elif (folder=='Brown spot'):\n",
        "      img_label[image] = np.asarray([0,0,1], dtype=np.float32)\n",
        "    else:\n",
        "      img_label[image] = np.asarray([0,1,0], dtype=np.float32)\n",
        " \n",
        "  os.chdir(previous_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4U54lUP6NPZ9"
      },
      "source": [
        "os.chdir('paddy_disease_classification/rice_leaf_diseases')\n",
        "\n",
        "img_label = {}\n",
        "\n",
        "for folder in training_classes:\n",
        "  create_dataset(folder)\n",
        "  \n",
        "\n",
        "os.chdir('/content')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-YSjS7HNPSr"
      },
      "source": [
        "print(img_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kPsNzqHQ_gU"
      },
      "source": [
        "\n",
        "def load_image(image_path):\n",
        "    '''\n",
        "      Converts the image to size = (299,299,3) and normalizes the data\n",
        "      Args : \n",
        "      image_path : str. Image path for processing the image\n",
        "    '''\n",
        "    img = tf.io.read_file(image_path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.resize(img, (299, 299))\n",
        "    # Normalizing the image\n",
        "    img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
        "    return img, image_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5_TOSCDQ_dy"
      },
      "source": [
        "# Test code for checking the image shape and max value of image\n",
        "os.chdir('paddy_disease_classification/train')\n",
        "image, path = load_image('DSC_0112blur.jpg')\n",
        "print(f\"image has a shape of {image.shape}\")\n",
        "print(tf.reduce_max(image))\n",
        "os.chdir('/content')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUKSdu0hRNw_"
      },
      "source": [
        "# differentiating the complete dataset into training and validating datasets.\n",
        "img_name_train, img_name_val, output_label_train, output_label_val = train_test_split(\n",
        "                                                                    list(img_label.keys()),\n",
        "                                                                    list(img_label.values()),\n",
        "                                                                    test_size=0.1,\n",
        "                                                                    random_state=0)\n",
        "\n",
        "print(f'Length of training images = {len(img_name_train)}')\n",
        "print(f'Length of training labels = {len(output_label_train)}')\n",
        "print(f\"Length of validating images = {len(img_name_val)}\")\n",
        "print(f'Length of validating labels = {len(output_label_val)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--oB771ZRNup"
      },
      "source": [
        "os.chdir('paddy_disease_classification/train')\n",
        "\n",
        "channels = 3\n",
        "\n",
        "train_images = np.ndarray(shape=(len(img_name_train), IMG_SHAPE, IMG_SHAPE, channels), dtype=np.float32)\n",
        "train_labels = np.ndarray(shape=(len(output_label_train), 3 ), dtype=np.float32)\n",
        "val_images = np.ndarray(shape=(len(img_name_val), IMG_SHAPE, IMG_SHAPE, channels), dtype=np.float32)\n",
        "val_labels = np.ndarray(shape=(len(output_label_val), 3 ), dtype=np.float32)\n",
        "\n",
        "i=0\n",
        "for image in tqdm(list(img_name_train)):\n",
        "  x, path = load_image(image)\n",
        "  train_images[i] = x\n",
        "  train_labels[i] = np.asarray(output_label_train[i])\n",
        "  i += 1\n",
        "\n",
        "\n",
        "i=0\n",
        "for image in tqdm(list(img_name_val)):\n",
        "  x, path = load_image(image)\n",
        "  val_images[i] = x\n",
        "  val_labels[i] = np.asarray(output_label_val[i])\n",
        "  i += 1\n",
        "\n",
        "os.chdir('/content')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m17crgDUnGjl"
      },
      "source": [
        "train_images.shape, train_labels.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-dKNHfkfyHP"
      },
      "source": [
        "os.chdir('paddy_disease_classification')\n",
        "!mkdir train\n",
        "os.chdir('/content')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haTgBsMefyHj"
      },
      "source": [
        "def create_dataset(folder):\n",
        "  previous_path = os.getcwd()\n",
        "  os.chdir(folder)\n",
        "  current_path = os.getcwd()\n",
        "  # for each image in the current directory\n",
        "  total_images = 0\n",
        "\n",
        "  for image in tqdm(list(os.listdir(current_path))):\n",
        "\n",
        "    shutil.move(image, \"/content/paddy_disease_classification/train\")\n",
        "\n",
        "    if (folder=='Bacterial leaf blight'):\n",
        "      img_label[image] = np.asarray([1,0,0], dtype=np.float32)\n",
        "    elif (folder=='Brown spot'):\n",
        "      img_label[image] = np.asarray([0,0,1], dtype=np.float32)\n",
        "    else:\n",
        "      img_label[image] = np.asarray([0,1,0], dtype=np.float32)\n",
        " \n",
        "  os.chdir(previous_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhPhjdKQfyHt"
      },
      "source": [
        "os.chdir('paddy_disease_classification/rice_leaf_diseases')\n",
        "\n",
        "img_label = {}\n",
        "\n",
        "for folder in training_classes:\n",
        "  create_dataset(folder)\n",
        "  \n",
        "\n",
        "os.chdir('/content')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3BVAZ0MfyH5"
      },
      "source": [
        "print(img_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwzW4v8wfyIB"
      },
      "source": [
        "\n",
        "def load_image(image_path):\n",
        "    '''\n",
        "      Converts the image to size = (299,299,3) and normalizes the data\n",
        "      Args : \n",
        "      image_path : str. Image path for processing the image\n",
        "    '''\n",
        "    img = tf.io.read_file(image_path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.resize(img, (299, 299))\n",
        "    # Normalizing the image\n",
        "    img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
        "    return img, image_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HX6c8d20fyIH"
      },
      "source": [
        "# Test code for checking the image shape and max value of image\n",
        "os.chdir('paddy_disease_classification/train')\n",
        "image, path = load_image('DSC_0112blur.jpg')\n",
        "print(f\"image has a shape of {image.shape}\")\n",
        "print(tf.reduce_max(image))\n",
        "os.chdir('/content')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnyEzvGofyIO"
      },
      "source": [
        "# differentiating the complete dataset into training and validating datasets.\n",
        "img_name_train, img_name_val, output_label_train, output_label_val = train_test_split(\n",
        "                                                                    list(img_label.keys()),\n",
        "                                                                    list(img_label.values()),\n",
        "                                                                    test_size=0.1)\n",
        "\n",
        "print(f'Length of training images = {len(img_name_train)}')\n",
        "print(f'Length of training labels = {len(output_label_train)}')\n",
        "print(f\"Length of validating images = {len(img_name_val)}\")\n",
        "print(f'Length of validating labels = {len(output_label_val)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJEgzTZhfyIU"
      },
      "source": [
        "os.chdir('paddy_disease_classification/train')\n",
        "\n",
        "channels = 3\n",
        "\n",
        "train_images = np.ndarray(shape=(len(img_name_train), IMG_SHAPE, IMG_SHAPE, channels), dtype=np.float32)\n",
        "train_labels = np.ndarray(shape=(len(output_label_train), 3 ), dtype=np.float32)\n",
        "val_images = np.ndarray(shape=(len(img_name_val), IMG_SHAPE, IMG_SHAPE, channels), dtype=np.float32)\n",
        "val_labels = np.ndarray(shape=(len(output_label_val), 3 ), dtype=np.float32)\n",
        "\n",
        "i=0\n",
        "for image in tqdm(list(img_name_train)):\n",
        "  x, path = load_image(image)\n",
        "  train_images[i] = x\n",
        "  train_labels[i] = np.asarray(output_label_train[i])\n",
        "  i += 1\n",
        "\n",
        "\n",
        "i=0\n",
        "for image in tqdm(list(img_name_val)):\n",
        "  x, path = load_image(image)\n",
        "  val_images[i] = x\n",
        "  val_labels[i] = np.asarray(output_label_val[i])\n",
        "  i += 1\n",
        "\n",
        "os.chdir('/content')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBvJId4yfyIZ"
      },
      "source": [
        "train_images.shape, train_labels.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F82PmT3Wh3tK"
      },
      "source": [
        "# Pre trained model \n",
        "inception_V3_pre_trained = InceptionV3(include_top=True, weights='imagenet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnFJvw3Fh3ye"
      },
      "source": [
        "for layer in inception_V3_pre_trained.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "predictions = Dense(3, activation='softmax')(inception_V3_pre_trained.output)\n",
        "inception_V3 = Model(inputs=inception_V3_pre_trained.input, outputs=predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6gEe3Qph31W"
      },
      "source": [
        "adam = tf.keras.optimizers.Adam(\n",
        "    learning_rate=0.00001, beta_1=0.9, beta_2=0.9999, epsilon=1e-08,\n",
        "    amsgrad=True, name='Adam' )\n",
        "\n",
        "inception_V3.compile(\n",
        "  optimizer=adam,\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['accuracy',tf.keras.metrics.AUC()])\n",
        "\n",
        "EPOCHS = 20\n",
        "history_inception_V3 = inception_V3.fit(\n",
        "    train_images, train_labels,\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=10,\n",
        "    validation_data=(val_images, val_labels)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItUxJVWZiEax"
      },
      "source": [
        "acc = history_inception_V3.history['accuracy']\n",
        "val_acc = history_inception_V3.history['val_accuracy']\n",
        "\n",
        "loss = history_inception_V3.history['loss']\n",
        "val_loss = history_inception_V3.history['val_loss']\n",
        "\n",
        "epochs_range = range(EPOCHS)\n",
        "plt.figure(num=None, figsize=(20,20), dpi=40, facecolor='w', edgecolor='k')\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label = 'validation Accuracy')\n",
        "plt.legend(loc='lower right',fontsize=20)\n",
        "plt.title('Accuracy Plot',fontsize=30)\n",
        "plt.xlabel('Number of Epochs',fontsize=30)\n",
        "plt.ylabel('Accuracy',fontsize=30)\n",
        "plt.xticks(fontsize=20)\n",
        "plt.yticks(fontsize=20)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label = 'validation Loss')\n",
        "plt.legend(loc='upper right',fontsize=20)\n",
        "plt.title('Loss Plot',fontsize=30)\n",
        "plt.xlabel('Number of Epochs',fontsize=30)\n",
        "plt.ylabel('Loss',fontsize=30)\n",
        "plt.xticks(fontsize=20)\n",
        "plt.yticks(fontsize=20)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZZLYmQiNeLx"
      },
      "source": [
        "def Get_Results_Inception_V3(folder):\n",
        "  ''' \n",
        "    Generates results for Inception_Resnet_V2 model\n",
        "      Folder : (str). : Image_directory\n",
        "  '''\n",
        "  previous_path = os.getcwd()\n",
        "  os.chdir(folder)\n",
        "  current_path = os.getcwd()\n",
        "  predicts = []\n",
        "\n",
        "  for image in tqdm(list(os.listdir(current_path))):\n",
        "    # img = cv2.imread(image)\n",
        "    # median = cv2.medianBlur(img, 5)\n",
        "    # im = Image.fromarray(median)\n",
        "    # im.save(image)\n",
        "\n",
        "    img = keras.preprocessing.image.load_img(image, target_size=(299,299, 3))\n",
        "    img = keras.preprocessing.image.img_to_array(img)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
        "\n",
        "    result_inception_v3['image_names'].append(image)\n",
        "    predicts.append(inception_V3.predict(img)[0])\n",
        "\n",
        "    if (folder=='Bacterial leaf blight'):\n",
        "      result_inception_v3['ground_truths'].append(np.asarray([1,0,0]))\n",
        "    elif (folder=='Brown spot'):\n",
        "      result_inception_v3['ground_truths'].append(np.asarray([0,0,1]))\n",
        "    else:\n",
        "      result_inception_v3['ground_truths'].append(np.asarray([0,1,0]))\n",
        "  \n",
        "  result_inception_v3['predictions'].append(predicts)\n",
        "  os.chdir(previous_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJBZNTYdNSRD"
      },
      "source": [
        "result_inception_v3 = {'predictions':[],'image_names':[],'ground_truths':[]}\n",
        "os.chdir('paddy_disease_classification/testing')\n",
        "\n",
        "for folder in training_classes:\n",
        "  Get_Results_Inception_V3(folder)\n",
        "\n",
        "os.chdir('/content')\n",
        "result_inception_v3['predictions'] = np.asarray(result_inception_v3['predictions']).reshape((60, 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erem_7veNSRi"
      },
      "source": [
        "print(np.asarray(result_inception_v3['ground_truths']))\n",
        "print(np.asarray(result_inception_v3['predictions']))\n",
        "print(np.asarray(result_inception_v3['ground_truths']).shape)\n",
        "print(np.asarray(result_inception_v3['predictions']).shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9TFl5C4NSRn"
      },
      "source": [
        "pred = np.asarray(result_inception_v3['predictions'])\n",
        "pred = np.argmax(pred, axis=1).reshape(-1)\n",
        "pred = np.asarray(np.eye(len(training_classes),dtype=int)[pred])\n",
        "print(pred)\n",
        "print(pred.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoTGHXXUNSRr"
      },
      "source": [
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(len(training_classes)):\n",
        "    fpr[i], tpr[i], _ = roc_curve(result_inception_v3['ground_truths'][i], result_inception_v3['predictions'][i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Compute micro-average ROC curve and ROC area\n",
        "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(np.asarray(result_inception_v3['ground_truths']).ravel(),np.asarray(result_inception_v3['predictions']).ravel())\n",
        "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LobYmmQNSRv"
      },
      "source": [
        "# First aggregate all false positive rates\n",
        "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(len(training_classes))]))\n",
        "\n",
        "# Then interpolate all ROC curves at this points\n",
        "mean_tpr = np.zeros_like(all_fpr)\n",
        "for i in range(len(training_classes)):\n",
        "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
        "\n",
        "# Finally average it and compute AUC\n",
        "mean_tpr /= len(training_classes)\n",
        "\n",
        "fpr[\"macro\"] = all_fpr\n",
        "tpr[\"macro\"] = mean_tpr\n",
        "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
        "\n",
        "# Plot all ROC curves\n",
        "lw = 2\n",
        "plt.figure()\n",
        "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
        "         label='micro-average ROC curve (area = {0:0.2f})'\n",
        "               ''.format(roc_auc[\"micro\"]),\n",
        "         color='deeppink', linestyle=':', linewidth=4)\n",
        "\n",
        "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
        "         label='macro-average ROC curve (area = {0:0.2f})'\n",
        "               ''.format(roc_auc[\"macro\"]),\n",
        "         color='navy', linestyle=':', linewidth=4)\n",
        "\n",
        "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
        "for i, color in zip(range(len(training_classes)), colors):\n",
        "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
        "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
        "             ''.format(i, roc_auc[i]))\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic using Inception-V3')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_CSzTjFNSRz"
      },
      "source": [
        "data = {'y_Actual': [np.where(r==1)[0][0] for r in np.asarray(result_inception_v3['ground_truths'])],\n",
        "        'y_Predicted': [np.where(r==1)[0][0] for r in pred]\n",
        "        }\n",
        "\n",
        "df = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\n",
        "confusion_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
        "\n",
        "sn.heatmap(confusion_matrix, annot=True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}